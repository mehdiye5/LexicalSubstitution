{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lexsub: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n"
     ]
    }
   ],
   "source": [
    "lexsub = LexSub(os.path.join('data','glove.6B.100d.magnitude'))\n",
    "output = []\n",
    "with open(os.path.join('data','input','dev.txt')) as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        output.append(\" \".join(lexsub.substitutes(int(fields[0].strip()), fields[1].strip().split())))\n",
    "print(\"\\n\".join(output[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=27.89\n"
     ]
    }
   ],
   "source": [
    "from lexsub_check import precision\n",
    "with open(os.path.join('data','reference','dev.out'), 'rt') as refh:\n",
    "    ref_data = [str(x).strip() for x in refh.read().splitlines()]\n",
    "print(\"Score={:.2f}\".format(100*precision(ref_data, output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "In order to run our program, you can simply call `./retrofit.sh` and then `./test.sh` in the terminal. You can also call the commands in order as follows.\n",
    "\n",
    "1. `python retrofit.py`\n",
    "2. `python3 -m pymagnitude.converter -i data/glove.6B.100d.retrofit.txt -o data/glove.6B.100d.retrofit.magnitude`\n",
    "3. `cp default.py answer/lexsub.py`\n",
    "4. `cp default.ipynb answer/lexsub.ipynb`\n",
    "5. `python3 zipout.py`\n",
    "6. `python3 check.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### retrofit.py\n",
    "\n",
    "The first file we wrote is called `retrofit.py`. This file updates the GLOVE word embeddings by looking at the wordnet ontology graph. This graph maps semantic relations between words, which we used to update the word vectors. By initially setting the Alpha and Beta to 1, we were able to achieve a baseline score of ~40.5.\n",
    "\n",
    "The next step we took was to perform hyperparameter tuning on Alpha and Beta. We attempted various weighting techniques here (exponential decay, linear, sin, etc), but these were attempted out of curiosity rather than logical reason. In the end, we found that simply keeping these values constant worked best. The optimal value for alpha was 0.11 and the optimal value of Beta was 0.975. This tuning of the hyperparameters resulted in a dev score of ~48.2 which was our best score.\n",
    "\n",
    "Another interesting strategy we tried was to use context words in addition to retrofitting. In our implementation, we simply added context vectors to the retrofitting embeddings and then renormalized the vectors. In theory, this should have increased the score we achieved on the dev set, but we could not achieve high accuracy with this method. Whether this was due to an incorrect normalization function, or an incorrect inference implementation we are not sure. The best score we were able to achieve here was ~0.28. \n",
    "\n",
    "As we were unable to include the context words in our predictions, the most similarly predicted words were constant based on the input. The result of this is shown below on the first three lines of dev.txt. The substituted word is \"side\".\n",
    "\n",
    "No Retrofitting\n",
    "```\n",
    "sides edge bottom front club line both back place corner\n",
    "sides edge bottom front club line both back place corner\n",
    "sides edge bottom front club line both back place corner\n",
    "```\n",
    "\n",
    "Retrofitting (No hyperparameter tuning)\n",
    "```\n",
    "edge position place line while front back along way on\n",
    "edge position place line while front back along way on\n",
    "edge position place line while front back along way on\n",
    "```\n",
    "\n",
    "Retrofitting (With hyperparameter tuning)\n",
    "```\n",
    "position point slope edge way heading line english place while\n",
    "position point slope edge way heading line english place while\n",
    "position point slope edge way heading line english place while\n",
    "```\n",
    "\n",
    "Context Based Similarity\n",
    "```\n",
    "already came were took they had having was been has\n",
    "already came were took they had having was been has\n",
    "already came were took they had having was been has\n",
    "```\n",
    "### default.py\n",
    "\n",
    "The retrofitted embeddings were computed using retrofit.py, and the context based similarity was implemented in default.py. We stored out best word embeddings in the `glove.6B.100d.retrofit.magnitude` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n",
      "edge position place line while front back along way on\n"
     ]
    }
   ],
   "source": [
    "lexsub = LexSub(os.path.join('data','glove.6B.100d.retrofit.magnitude'))\n",
    "output = []\n",
    "with open(os.path.join('data','input','dev.txt')) as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        output.append(\" \".join(lexsub.substitutes(int(fields[0].strip()), fields[1].strip().split())))\n",
    "print(\"\\n\".join(output[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n",
      "position point slope edge way heading line english place while\n"
     ]
    }
   ],
   "source": [
    "lexsub = LexSub(os.path.join('data','glove.6B.100d.retrofitTOP.magnitude'))\n",
    "output = []\n",
    "with open(os.path.join('data','input','dev.txt')) as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        output.append(\" \".join(lexsub.substitutes(int(fields[0].strip()), fields[1].strip().split())))\n",
    "print(\"\\n\".join(output[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
